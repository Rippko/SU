{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import time\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementace DecisionTree a RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(set(y))\n",
    "        self.n_features = X.shape[1]\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(inputs) for inputs in X])\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        if n_samples <= 1 or depth >= self.max_depth or len(set(y)) == 1:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feat_idxs = np.random.choice(n_features, self.n_features, replace=False)\n",
    "\n",
    "        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
    "\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "\n",
    "    def _best_criteria(self, X, y, feat_idxs):\n",
    "        best_gain = -1\n",
    "        split_idx, split_thresh = None, None\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y, X_column, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_thresh = threshold\n",
    "        return split_idx, split_thresh\n",
    "\n",
    "    def _information_gain(self, y, X_column, split_thresh):\n",
    "        parent_entropy = self._entropy(y)\n",
    "        left_idxs, right_idxs = self._split(X_column, split_thresh)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n",
    "        ig = parent_entropy - child_entropy\n",
    "        return ig\n",
    "\n",
    "    def _split(self, X_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        return most_common\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree\n",
    "        while node.left or node.right:\n",
    "            node = node.left if inputs[node.feature] <= node.threshold else node.right\n",
    "        return node.value\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=100, max_depth=None, n_features=None, random_state=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "        if random_state:\n",
    "            np.random.seed(random_state)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
    "        y_pred = [self._most_common_label(tree_pred) for tree_pred in tree_preds]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        if X.shape[0] == 0 or len(y) == 0:\n",
    "            raise ValueError(\"Bootstrap sample failed due to empty dataset.\")\n",
    "        n_samples = X.shape[0]\n",
    "        idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X[idxs], y[idxs]\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        return most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Načtení základního datasetu pro testování implementace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- jednoduchý preprocessing v rámci datasetu `titanic.csv`, aby byl vhodný pro klasifikační testování.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- doplnění chybějících hodnot v příslušných sloupcích a následný encoding s pomocí **LabelEncoder**\n",
    "- vytvoření target proměnné `Survived` a vytvoření `train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.fillna({'Age': titanic['Age'].mean()}, inplace=True)\n",
    "titanic.fillna({'Embarked':titanic['Embarked'].mode()[0]}, inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "titanic['Sex'] = label_encoder.fit_transform(titanic['Sex'])\n",
    "titanic['Embarked'] = label_encoder.fit_transform(titanic['Embarked'])\n",
    "\n",
    "\n",
    "X_titanic = titanic.drop(columns=['Survived']).values\n",
    "y_titanic = titanic['Survived'].values\n",
    "\n",
    "X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = train_test_split(X_titanic, y_titanic, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testování vlastní implementace RandomForest algoritmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic Dataset Performance Metrics:\n",
      "+-----------+--------------------+\n",
      "|   Metric  |       Value        |\n",
      "+-----------+--------------------+\n",
      "|  Accuracy | 0.8156424581005587 |\n",
      "| Precision | 0.847457627118644  |\n",
      "|   Recall  | 0.6756756756756757 |\n",
      "|  F1 Score | 0.7518796992481203 |\n",
      "+-----------+--------------------+\n",
      "\n",
      "Time Analysis:\n",
      "+--------------+----------------------+\n",
      "|    Stage     |    Time (seconds)    |\n",
      "+--------------+----------------------+\n",
      "|   Fit Time   |  17.093661308288574  |\n",
      "| Predict Time | 0.031196117401123047 |\n",
      "|  Total Time  |  17.124857425689697  |\n",
      "+--------------+----------------------+\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       105\n",
      "           1       0.85      0.68      0.75        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.79      0.80       179\n",
      "weighted avg       0.82      0.82      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_fit = time.time()\n",
    "rf_titanic = RandomForest(n_trees=100, max_depth=10, random_state=42)\n",
    "rf_titanic.fit(X_train_titanic, y_train_titanic)\n",
    "end_fit = time.time()\n",
    "\n",
    "start_predict = time.time()\n",
    "y_pred_titanic = rf_titanic.predict(X_test_titanic)\n",
    "end_predict = time.time()\n",
    "\n",
    "accuracy_titanic = accuracy_score(y_test_titanic, y_pred_titanic)\n",
    "precision_titanic = precision_score(y_test_titanic, y_pred_titanic, average='binary')\n",
    "recall_titanic = recall_score(y_test_titanic, y_pred_titanic, average='binary')\n",
    "f1_titanic = f1_score(y_test_titanic, y_pred_titanic, average='binary')\n",
    "\n",
    "fit_time = end_fit - start_fit\n",
    "predict_time = end_predict - start_predict\n",
    "total_time = fit_time + predict_time\n",
    "\n",
    "table_metrics = PrettyTable()\n",
    "table_metrics.field_names = [\"Metric\", \"Value\"]\n",
    "table_metrics.add_row([\"Accuracy\", accuracy_titanic])\n",
    "table_metrics.add_row([\"Precision\", precision_titanic])\n",
    "table_metrics.add_row([\"Recall\", recall_titanic])\n",
    "table_metrics.add_row([\"F1 Score\", f1_titanic])\n",
    "\n",
    "table_time = PrettyTable()\n",
    "table_time.field_names = [\"Stage\", \"Time (seconds)\"]\n",
    "table_time.add_row([\"Fit Time\", fit_time])\n",
    "table_time.add_row([\"Predict Time\", predict_time])\n",
    "table_time.add_row([\"Total Time\", total_time])\n",
    "\n",
    "print(\"Titanic Dataset Performance Metrics:\")\n",
    "print(table_metrics)\n",
    "print(\"\\nTime Analysis:\")\n",
    "print(table_time)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_titanic, y_pred_titanic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testování implementace RandomForest algoritmu z knihovny sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic Dataset Performance Metrics:\n",
      "+-----------+--------------------+\n",
      "|   Metric  |       Value        |\n",
      "+-----------+--------------------+\n",
      "|  Accuracy | 0.8268156424581006 |\n",
      "| Precision | 0.8412698412698413 |\n",
      "|   Recall  | 0.7162162162162162 |\n",
      "|  F1 Score | 0.7737226277372263 |\n",
      "+-----------+--------------------+\n",
      "\n",
      "Time Analysis:\n",
      "+--------------+----------------------+\n",
      "|    Stage     |    Time (seconds)    |\n",
      "+--------------+----------------------+\n",
      "|   Fit Time   |  0.1494295597076416  |\n",
      "| Predict Time | 0.006574153900146484 |\n",
      "|  Total Time  | 0.15600371360778809  |\n",
      "+--------------+----------------------+\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       105\n",
      "           1       0.84      0.72      0.77        74\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.83      0.81      0.82       179\n",
      "weighted avg       0.83      0.83      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_fit = time.time()\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_clf.fit(X_train_titanic, y_train_titanic)\n",
    "end_fit = time.time()\n",
    "\n",
    "start_predict = time.time()\n",
    "y_pred_titanic_clf = rf_clf.predict(X_test_titanic)\n",
    "end_predict = time.time()\n",
    "\n",
    "accuracy_titanic_clf = accuracy_score(y_test_titanic, y_pred_titanic_clf)\n",
    "precision_titanic_clf = precision_score(y_test_titanic, y_pred_titanic_clf, average='binary')\n",
    "recall_titanic_clf = recall_score(y_test_titanic, y_pred_titanic_clf, average='binary')\n",
    "f1_titanic_clf = f1_score(y_test_titanic, y_pred_titanic_clf, average='binary')\n",
    "\n",
    "fit_time = end_fit - start_fit\n",
    "predict_time = end_predict - start_predict\n",
    "total_time = fit_time + predict_time\n",
    "\n",
    "table_metrics = PrettyTable()\n",
    "table_metrics.field_names = [\"Metric\", \"Value\"]\n",
    "table_metrics.add_row([\"Accuracy\", accuracy_titanic_clf])\n",
    "table_metrics.add_row([\"Precision\", precision_titanic_clf])\n",
    "table_metrics.add_row([\"Recall\", recall_titanic_clf])\n",
    "table_metrics.add_row([\"F1 Score\", f1_titanic_clf])\n",
    "\n",
    "table_time = PrettyTable()\n",
    "table_time.field_names = [\"Stage\", \"Time (seconds)\"]\n",
    "table_time.add_row([\"Fit Time\", fit_time])\n",
    "table_time.add_row([\"Predict Time\", predict_time])\n",
    "table_time.add_row([\"Total Time\", total_time])\n",
    "\n",
    "print(\"Titanic Dataset Performance Metrics:\")\n",
    "print(table_metrics)\n",
    "print(\"\\nTime Analysis:\")\n",
    "print(table_time)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_titanic, y_pred_titanic_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Závěr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Srovnání výkonu vlastní implementace Random Forest a RandomForestClassifier\n",
    "\n",
    "### Metriky měření přesnosti v %\n",
    "\n",
    "| Metrika        | Vlastní implementace | Scikit-learn implementace |\n",
    "|----------------|----------------------|---------------------------|\n",
    "| **Accuracy**   | 81.56 %             | 82.68 %                  |\n",
    "| **Precision** | 84.75 %             | 84.13 %                  |\n",
    "| **Recall**   | 67.57 %             | 71.62 %                  |\n",
    "| **F1 Score**   | 75.19 %             | 77.37 %                  |\n",
    "\n",
    "**Závěr:** \n",
    "- Scikit-learn implementace dosahuje o něco lepších výsledků ve všech metrikách, zejména v Recall a F1 score.\n",
    "\n",
    "---\n",
    "\n",
    "### Časová náročnost pro počet stromů 100 a hloubka stromů 10\n",
    "\n",
    "| Fáze           | Vlastní implementace (s) | Scikit-learn implementace (s) |\n",
    "|----------------|--------------------------|-------------------------------|\n",
    "| **Trénování**  | 17.06                   | 0.14                          |\n",
    "| **Predikce**   | 0.03                    | 0.006                         |\n",
    "| **Celkem**     | 17.09                   | 0.15                          |\n",
    "\n",
    "**Závěr:** \n",
    "- Scikit-learn implementace je výrazně rychlejší při trénování (více než 100x rychlejší) i při predikci.\n",
    "\n",
    "---\n",
    "\n",
    "### Shrnutí\n",
    "\n",
    "1. **Výkon metrik:** Scikit-learn implementace poskytuje lepší přesnost, recall a F1 skóre, avšak vhledem k rozdílu v komplexnosti implementace a možnosti nastavení volitelných parametrů u verze z knihovny, lze konstatovat, že přesnost vlastní implementace je do jisté míry uspokojivá.  \n",
    "2. **Rychlost:** Scikit-learn implementace je výrazně rychlejší díky optimalizacím knihovny a paralelnímu zpracování.  \n",
    "3. **Možnosti vylepšení vlastní implementace:**  \n",
    "   - **Optimalizace výběru vlastností a prahových hodnot:**  \n",
    "     Místo výpočtu všech prahů pomocí `np.unique` lze zkusit vzorkování prahů nebo zmenšit počet zkoumaných prahů pomocí binování dat.\n",
    "   - **Vektorové výpočty:**  \n",
    "     Přepsání výpočtů entropie, informačního zisku a rozdělení na vektorovou podobu s využitím NumPy.\n",
    "   - **Parallelizace:**  \n",
    "     Využití paralelního zpracování stromů pomocí knihovny `joblib` nebo `concurrent.futures` k urychlení trénování Random Forest.\n",
    "   - **Efektivní bootstrap sampling:**  \n",
    "     Nahrazení `np.random.choice` efektivnějším `np.random.randint`, aby se minimalizovalo zpracování velkých datasetů.\n",
    "   - **Optimalizace stromové struktury:**  \n",
    "     Ukládání dat stromu jako NumPy pole místo rekurzivní struktury uzlů ke zlepšení přístupové rychlosti.\n",
    "   - **Použití nízkoúrovňové optimalizace:**  \n",
    "     Přepsání kritických částí pomocí Cython nebo Numba pro rychlejší výpočty.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
